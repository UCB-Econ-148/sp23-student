{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db623c0a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab09.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc77e4b1",
   "metadata": {},
   "source": [
    "# Lab 9: Time Series\n",
    "### Using Zillow to Predict CPI\n",
    "In this notebook, we're going to try to use data from Zillow (specifically, their ZORI index) to see if we can use it to predict the US consumer price index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b884e471",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Introduction and Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adfc796",
   "metadata": {},
   "source": [
    "### Dataset 1: ZORI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf717e91",
   "metadata": {},
   "source": [
    "We've downloaded the ZORI index for you from [Zillow Research Data](https://www.zillow.com/research/data/). Run the following cell to display information about the ZORI index. What can you tell from the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd1a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "zori = pd.read_csv(\"zori1.csv\")\n",
    "zori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec9fa62",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.1:** What information is stored in the ZORI data? What does each row represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f39d733",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433a2570",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.2:** If we wanted to compared ZORI data against US CPI, what might be some ways we can manipulate our data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e1c30",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e088ebc",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Below, we select row within the ZORI dataframe that has the timeseries corresponding to the ZORI index for the entire country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9db04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zUS = zori.iloc[[0], :-1]\n",
    "zUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b501d65",
   "metadata": {},
   "source": [
    "We notice that the dates in the timeseries actually start from the 6th entry in the index. If we wanted to create a DataFrame, we would need to find a way to extract this information, in addition to the data stored in the ZORI column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca013e8e",
   "metadata": {},
   "source": [
    "**Question 1.3:** Transpose the dataframe and select the relevant rows. Then rename the column names to `DATE` and `ZORI`. \n",
    "\n",
    "Hint: `df.T` can transpose a dataframe `df`. \n",
    "The resulting dataframe `zillow` should look like the following:\n",
    "\n",
    "| DATE | ZORI |\n",
    "| ----------- | ----------- |\n",
    "| 2015-03-31 | 1370.301806 |\n",
    "| 2015-04-30 | 1381.971304 |\n",
    "|  | ... (rows omitted) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343b567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zillow = ... # transpose the dataframe `zUS`\n",
    "zillow = ... # select relevant rows\n",
    "zillow = zillow.reset_index()\n",
    "zillow = ... # rename the columns\n",
    "zillow['DATE'] = pd.to_datetime(zillow['DATE'], format='%Y-%m-%d') # convert date column to datatime objects\n",
    "zillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edda2ac",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8a5015",
   "metadata": {},
   "source": [
    "We might wonder what this looks like. Let's graph this time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff27a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data=zillow, x=\"DATE\", y=\"ZORI\")\n",
    "plt.title(\"ZORI Index\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a252567e",
   "metadata": {},
   "source": [
    "Do you notice anything interesting about this graph? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe2986c",
   "metadata": {},
   "source": [
    "We'll focus on the part where the slope becomes noticably steeper. Can you find around what time this happened? What are some possible explanations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df992fc9",
   "metadata": {},
   "source": [
    "### Dataset 2: US CPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65016ce9",
   "metadata": {},
   "source": [
    "We'll now bring our attention to the US CPI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78e337b",
   "metadata": {},
   "source": [
    "We've downloaded historical **US CPI data for rent of primary residence** from the [FRED website](https://fred.stlouisfed.org/series/CUUR0000SEHA). Since our ZORI data starts on 03/31/2015, we've adjusted the sliders on the FRED website to only extract starting from 03/31/2015. We've also renamed the columns to be more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d49678",
   "metadata": {},
   "outputs": [],
   "source": [
    "usCPI = pd.read_csv(\"usCPI.csv\")\n",
    "usCPI = usCPI.rename(columns={\"CUUR0000SEHA\": \"CPI\"})\n",
    "usCPI = usCPI.iloc[1:, :]\n",
    "usCPI['DATE'] = pd.to_datetime(usCPI['DATE'], format='%Y-%m-%d')\n",
    "usCPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e064cd8c",
   "metadata": {},
   "source": [
    "We can try plotting this to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632b2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=usCPI, x=\"DATE\", y=\"CPI\")\n",
    "plt.title(\"US CPI (Rent of Primary Residence)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36320422",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667541d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set `DATE` as the index\n",
    "zillow = zillow.set_index('DATE')\n",
    "usCPI = usCPI.set_index('DATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4f3b40",
   "metadata": {},
   "source": [
    "**Question 1.4:** Let's split the `usCPI` dataframe into a training set and testing set. Put all data before Jan. 1st, 2022 into the training set, and all data on or after Jan. 1st, 2022 into the testing set. \n",
    "\n",
    "Note: This is not how normally we do the train-test split. In a normal setup, we would assign a random portion of the data to training set and the rest to testing set. But in this analysis, we care about how well can we predict the future values using current values, so here's how we do the train-test split. \n",
    "\n",
    "Hint: You can use `pd.to_datetime(\"2022-01-01\", format='%Y-%m-%d')` to generate a timestamp for comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d96d761",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = ...\n",
    "test = ...\n",
    "plt.plot(train['CPI'], color = \"black\", label='Train')\n",
    "plt.plot(test['CPI'], color = \"red\", label='Test')\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Date')\n",
    "plt.title(\"Train/Test split for US CPI Data\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c3bb5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42505edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate train test CPI series\n",
    "y_train = train['CPI']\n",
    "y_test = test['CPI']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a51f91",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Time Series Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9b03eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ea956d",
   "metadata": {},
   "source": [
    "### Review\n",
    "Let $X_t$ be a sequence of random variables that describes a time series model. \n",
    "\n",
    "* **Random walk**:   \n",
    "A random walk is a time series model where the current observation is equal to the previous observation with a random step up or down. The model is widely used for non-stationary data, particularly financial and economic data.\n",
    "\n",
    "$$X_t = X_{t-1} + \\varepsilon_t$$ \n",
    "\n",
    "* **Random walk with drift**:   \n",
    "If the random walk has a non-zero dift and acts like a trend, we will add an additional drift term ($\\alpha$) to the process. \n",
    "\n",
    "$$X_t = X_{t-1} + \\alpha + \\varepsilon_t$$ \n",
    "\n",
    "* **Autoregressive (AR)**: AR(p) refers to the autoregressive model of order p.  \n",
    "The autoregressive model uses observations from preivous time steps as input to a regression equations to predict the value at the next step. The AR model takes in one argument, p, which determines how many previous time steps will be inputted.\n",
    "\n",
    "$$X_t = c + \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + \\cdots + \\phi_p X_{t-p} + \\varepsilon_t$$ \n",
    "\n",
    "* **Moving-average (MA)**: MA(q) refers to the moving average model of order q. \n",
    "The moving average model is a time series model that accounts for very short-run autocorrelation. \n",
    "\n",
    "$$X_t = \\mu + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\cdots + \\theta_q \\varepsilon_{t-q}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9285fa59",
   "metadata": {},
   "source": [
    "### Autoregressive Moving Average (ARMA)\n",
    "The notation ARMA(p, q) refers to the model with p autoregressive terms and q moving-average terms. This model contains the AR(p) and MA(q) models. \n",
    "\n",
    "$$X_t = c + \\underbrace{\\phi_1 X_{t-1} + \\phi_2 X_{t-2} + \\cdots + \\phi_p X_{t-p}}_{AR(p)} + \\underbrace{\\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\cdots + \\theta_q \\varepsilon_{t-q}}_{MA(q)} + \\varepsilon_t $$ \n",
    "\n",
    "Here's a summary table for the relationship between ARIMA model and the models discussed. \n",
    "\n",
    "| Model | ARMA(p, q) |\n",
    "| ----------- | ----------- |\n",
    "| White noise | ARMA(0,0) |\n",
    "| Autoregression (AR(p)) | ARMA(p,0) |\n",
    "| Moving average (MA(q)) | ARMA(0,q) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9d3874",
   "metadata": {},
   "source": [
    "Now let's try fit our data using ARMA(1, 1), which is saying we want to fit our CPI data to the following process:\n",
    "\n",
    "$$CPI_t = c + \\underbrace{\\phi_1 CPI_{t-1}}_{AR(1)} + \\underbrace{\\theta_1 \\varepsilon_{t-1}}_{MA(1)} + \\varepsilon_t $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040da1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARMAmodel = ARIMA(y_train, order = (1, 0, 1)) # ARMA(1, 1). See ARIMA (next section) for why there's a zero\n",
    "ARMAmodel = ARMAmodel.fit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c952a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ARMAmodel.get_forecast(len(test.index))\n",
    "y_pred_df = y_pred.conf_int(alpha = 0.05) # 95% CI\n",
    "y_pred_df[\"Predictions\"] = ARMAmodel.predict(start = y_pred_df.index[0], end = y_pred_df.index[-1])\n",
    "y_pred_df.index = test.index\n",
    "y_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8f8c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions series\n",
    "y_pred_out = y_pred_df[\"Predictions\"]\n",
    "\n",
    "# Plot\n",
    "plt.plot(train, color = 'black')\n",
    "plt.plot(test, color = 'red', label = 'Actual')\n",
    "plt.plot(y_pred_out, color='green', label = 'Predictions')\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Predictions US CPI Data\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c620d",
   "metadata": {},
   "source": [
    "**Question 2.1:** Why does the predictions look almost constant?\n",
    "\n",
    "1. Because ARMA is a bad model for this time series\n",
    "2. Because we did not give ARMA a reasonable set of orders (i.e. p and q)\n",
    "3. Because the data is too volatile to predict\n",
    "\n",
    "Assign the number corresponding to your answer to `q2_1` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a638c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q2_1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb29abe",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a52bc92",
   "metadata": {},
   "source": [
    "We can also compute the loss of this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e554f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_rmse = np.sqrt(mean_squared_error(test[\"CPI\"].values, y_pred_df[\"Predictions\"]))\n",
    "print(\"RMSE: \",arma_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ef590",
   "metadata": {},
   "source": [
    "### Autoregressive Integrated Moving Average (ARIMA)\n",
    "\n",
    "The notation ARIMA(p, d, q) refers to the model with p autoregressive terms with d degree of differencing and q moving-average terms. \n",
    "\n",
    "$$X_t' = c + \\underbrace{\\phi_1 X_{t-1}' + \\phi_2 X_{t-2}' + \\cdots + \\phi_p X_{t-p}'}_{AR(p)} + \\underbrace{\\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\cdots + \\theta_q \\varepsilon_{t-q}}_{MA(q)} + \\varepsilon_t $$ \n",
    "\n",
    "where $y_t'$ is the differenced series (it may have been differenced more than once).\n",
    "\n",
    "**Difference between ARMA and ARIMA**: The only difference is the “integrated” part. Integrated refers to the number of times needed to difference a series in order to achieve stationarity, which is required for ARMA models to be valid. So ARMA is a special case of ARIMA with $d = 0$. ARIMA models are widely used for real life time series analysis since most times series data are non stationary and need differencing.\n",
    "\n",
    "Here's a summary table for the relationship between ARIMA model and the models discussed. \n",
    "\n",
    "| Model | ARIMA(p, d, q) |\n",
    "| ----------- | ----------- |\n",
    "| White noise | ARIMA(0,0,0) |\n",
    "| Random walk | ARIMA(0,1,0) with no constant |\n",
    "| Random walk with drift | ARIMA(0,1,0) with a constant |\n",
    "| Autoregression (AR(p)) | ARIMA(p,0,0) |\n",
    "| Moving average (MA(q)) | ARIMA(0,0,q) |\n",
    "| Autoregressive Moving Average (ARMA(p,q)) | ARIMA(p,0,q) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718e3045",
   "metadata": {},
   "source": [
    "Now let's try fit our data using $\\text{ARIMA}(1, 1, 1)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da68a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARIMAmodel_naive = ARIMA(y_train, order = (1, 1, 1))\n",
    "ARIMAmodel_naive = ARIMAmodel_naive.fit()\n",
    "\n",
    "y_pred = ARIMAmodel_naive.get_forecast(len(test.index))\n",
    "y_pred_df = y_pred.conf_int(alpha = 0.05) \n",
    "y_pred_df[\"Predictions\"] = ARIMAmodel_naive.predict(start = y_pred_df.index[0], end = y_pred_df.index[-1])\n",
    "y_pred_df.index = test.index\n",
    "y_pred_out = y_pred_df[\"Predictions\"] \n",
    "plt.plot(train, color = \"black\")\n",
    "plt.plot(test, color = \"red\", label = 'Actual')\n",
    "plt.plot(y_pred_out, color='blue', label = 'ARIMA(1, 1, 1) Predictions')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301aa700",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_naive_rmse = np.sqrt(mean_squared_error(test[\"CPI\"].values, y_pred_df[\"Predictions\"]))\n",
    "print(\"RMSE: \",arima_naive_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e64bee",
   "metadata": {},
   "source": [
    "After adding $d=1$ differencing, the predictions look much better than before!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edd4834",
   "metadata": {},
   "source": [
    "However, the ARIMA model for time series analysis and forecasting can be tricky to configure.\n",
    "\n",
    "There are 3 parameters (p, d and q) that require estimation by iterative trial and error from reviewing diagnostic plots and using 40-year-old heuristic rules. Usually we will find optimal parameters with ACF, PACF plots, and BIC/AIC information criteria or simply do a grid search, but we will not go into depth about these topics here. If you are interested, you can learn more about this in Stat 153. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e53eb",
   "metadata": {},
   "source": [
    "**Question 2.2:** Let's find some better parameters using trial and error. Try some combinations of p, d and q and see what is the result of the predictions. To pass the autograder, you only need to get RMSE of your model under 3.5. \n",
    "\n",
    "Hint: Think about what does p, d, q mean in the ARIMA model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23b5095",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ARIMAmodel = ... # specify the model\n",
    "ARIMAmodel = ... # fit the model\n",
    "\n",
    "# generate predictions\n",
    "y_pred = ARIMAmodel.get_forecast(len(test.index))\n",
    "y_pred_df = y_pred.conf_int(alpha = 0.05) \n",
    "y_pred_df[\"Predictions\"] = ARIMAmodel.predict(start = y_pred_df.index[0], end = y_pred_df.index[-1])\n",
    "y_pred_df.index = test.index\n",
    "y_pred_out = y_pred_df[\"Predictions\"] \n",
    "\n",
    "# plot\n",
    "plt.plot(train, color = \"black\")\n",
    "plt.plot(test, color = \"red\", label = 'Actual')\n",
    "plt.plot(y_pred_out, color='blue', label = 'ARIMA Predictions')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9867cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arima_rmse = np.sqrt(mean_squared_error(test[\"CPI\"].values, y_pred_df[\"Predictions\"]))\n",
    "print(\"RMSE: \",arima_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a6ed23",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3b953e",
   "metadata": {},
   "source": [
    "However, in real world when we don't know the future values, such tuning can lead to overfitting. So we need to be aware of the bia-variance tradeoff when tuning our time series model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4676856a",
   "metadata": {},
   "source": [
    "### Seasonal Autoregressive Integrated Moving Average (SARIMA)\n",
    "So far, we have restricted our attention to non-seasonal data and non-seasonal ARIMA models. However, ARIMA models are also capable of modelling a wide range of seasonal data.\n",
    "\n",
    "A seasonal ARIMA model is formed by including additional seasonal terms in the ARIMA models we have seen so far. It is written as follows:\n",
    "\n",
    "$$\\text{ARIMA} (p, d, q) (P, D, Q)_m$$\n",
    "\n",
    "where $m$ is the number of observations per year. For example, $m=12$ is for monthly data and $m=4$ is for quarterly data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec77a2d9",
   "metadata": {},
   "source": [
    "**Question 2.3:** What should $m$ be for our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa22559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b73967",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4106a002",
   "metadata": {},
   "source": [
    "Let's try fit our data using $\\text{ARIMA} (5, 4, 2) (2, 2, 2)_{m}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b042b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SARIMAXmodel = SARIMAX(y_train, order = (5, 4, 2), seasonal_order=(2,2,2,m))\n",
    "SARIMAXmodel = SARIMAXmodel.fit(disp=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec4c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SARIMAXmodel.get_forecast(len(test.index))\n",
    "y_pred_df = y_pred.conf_int(alpha = 0.05) \n",
    "y_pred_df[\"Predictions\"] = SARIMAXmodel.predict(start = y_pred_df.index[0], end = y_pred_df.index[-1])\n",
    "y_pred_df.index = test.index\n",
    "y_pred_out = y_pred_df[\"Predictions\"] \n",
    "plt.plot(train, color = \"black\")\n",
    "plt.plot(test, color = \"red\", label = 'Actual')\n",
    "plt.plot(y_pred_out, color='Blue', label = 'SARIMA Predictions')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097e5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_rmse = np.sqrt(mean_squared_error(test[\"CPI\"].values, y_pred_df[\"Predictions\"]))\n",
    "print(\"RMSE: \",sarima_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630dcae4",
   "metadata": {},
   "source": [
    "**Question 2.4:** It seems that the SARIMA model doesn't help too much with our predictions. Why?\n",
    "\n",
    "1. Because SARIMA is not an improvement to ARIMA for this time series\n",
    "2. Because we did not give SARIMA a reasonable set of orders\n",
    "3. Because the data is too volatile to predict\n",
    "\n",
    "Assign the number corresponding to your answer to `q2_4` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a5788f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q2_4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebc856a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da093b1b",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Time Series with Multiple Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6ad4e6",
   "metadata": {},
   "source": [
    "We want to combine both time series so that we can analyze them together. However, we notice that the `DATE` column has different values. ZORI is measured on the 31st of each month, while CPI is measured on the 1st day of each month. For our purposes, we can combine the two by using the `DATE` index from the US CPI and using the 1st day of the month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad8de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([zillow.reset_index(drop=True), usCPI.reset_index(drop=True)], axis=1)\n",
    "combined.index = usCPI.index\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc97771d",
   "metadata": {},
   "source": [
    "### Visual Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ca65d1",
   "metadata": {},
   "source": [
    "We can try plotting this graph to see if we can find anything interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462820a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data=combined, x=\"DATE\", y=\"CPI\", color='tab:blue', label='CPI')\n",
    "ax2 = plt.twinx()\n",
    "sns.lineplot(data=combined, x=\"DATE\", y=\"ZORI\", color='tab:orange', ax=ax2, label='ZORI')\n",
    "plt.legend(loc='upper left')\n",
    "ax2.legend(loc='lower right')\n",
    "plt.title(\"US CPI vs ZORI\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93469a46",
   "metadata": {},
   "source": [
    "#### Logging Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdac37f0",
   "metadata": {},
   "source": [
    "We can try logging our data to make them easier to compare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5171e3d",
   "metadata": {},
   "source": [
    "**Question 3.1:** Take the natural log for `CPI` and `ZORI` and store the results in new columns `log CPI` and `log ZORI`. Then make a plot similar to the one above. \n",
    "\n",
    "Hint: You may want to convert both column `ZORI` and `CPI` to `float64` before taking the natural log. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17fe5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "combined[\"log CPI\"] = ...\n",
    "...\n",
    "combined[\"log ZORI\"] = ...\n",
    "\n",
    "sns.lineplot(..., color='tab:blue', label='log CPI')\n",
    "plt.ylim([5.6, 6.1])\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "ax2 = plt.twinx()\n",
    "sns.lineplot(..., color='tab:orange', ax=ax2, label='log ZORI')\n",
    "ax2.set_ylim([7.2, 7.7])\n",
    "ax2.legend(loc='lower right')\n",
    "plt.title(\"US CPI vs ZORI (Logged)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7584149d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3d73a3",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 3.2:** Which time series is more volatile? What can be one possible explanation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ee5980",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a2254",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b52d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation\n",
    "rho, pvalue = stats.pearsonr(combined[\"log CPI\"], combined[\"log ZORI\"])\n",
    "print(\"Correlation: \", rho)\n",
    "print(\"P-value: \", pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9e5c96",
   "metadata": {},
   "source": [
    "### Vector Autoregressive (VAR) Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279d7143",
   "metadata": {},
   "source": [
    "One limitation of the models that we have considered so far is that they impose a unidirectional relationship — the forecast variable is influenced by the predictor variables, but not vice versa. However, there are many cases where the reverse should also be allowed for — where all variables affect each other. For example, in our case CPI and ZORI can be predictor for each other since they are highly correlated series.  \n",
    "\n",
    "A VAR model is a generalization of the univariate autoregressive model for forecasting a vector of time series. We will not go into the math behind VAR model in this class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe3d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statsmodels packages\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tools.eval_measures import rmse, aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b19b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df = combined[[\"CPI\", \"ZORI\"]]\n",
    "var_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5865685c",
   "metadata": {},
   "source": [
    "#### Splitting into Training and Testing Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb697a8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nobs = 4\n",
    "df_train, df_test = var_df[0:-nobs], var_df[-nobs:]\n",
    "\n",
    "# Check size\n",
    "print(df_train.shape) \n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f27d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23de4894",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 1: Checking Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f602e8fb",
   "metadata": {},
   "source": [
    "#### Granger Causality\n",
    "We first use Granger's Causality Tests to see the p-value of the correlations between different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968fc767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "maxlag=12\n",
    "test = 'ssr_chi2test'\n",
    "def grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False):    \n",
    "    \"\"\"Check Granger Causality of all possible combinations of the Time series.\n",
    "    The rows are the response variable, columns are predictors. The values in the table \n",
    "    are the P-Values. P-Values lesser than the significance level (0.05), implies \n",
    "    the Null Hypothesis that the coefficients of the corresponding past values is \n",
    "    zero, that is, the X does not cause Y can be rejected.\n",
    "\n",
    "    data      : pandas dataframe containing the time series variables\n",
    "    variables : list containing names of the time series variables.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n",
    "            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "            min_p_value = np.min(p_values)\n",
    "            df.loc[r, c] = min_p_value\n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc23f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "grangers_causation_matrix(var_df, variables = var_df.columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1adbdc8",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 3.3:** How can we interpret the findings above?\n",
    "\n",
    "Hint: Read the docstring for the function `grangers_causation_matrix`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00180456",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fa17a2",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "#### Cointegration Test\n",
    "We can also use a cointegration test to see if the two time series are correlated before making any predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17147a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "\n",
    "def cointegration_test(df, alpha=0.05): \n",
    "    \"\"\"Perform Johanson's Cointegration Test and Report Summary\"\"\"\n",
    "    out = coint_johansen(df,-1,5)\n",
    "    d = {'0.90':0, '0.95':1, '0.99':2}\n",
    "    traces = out.lr1\n",
    "    cvts = out.cvt[:, d[str(1-alpha)]]\n",
    "    def adjust(val, length= 6): return str(val).ljust(length)\n",
    "\n",
    "    # Summary\n",
    "    print('Name   ::  Test Stat > C(95%)    =>   Signif  \\n', '--'*20)\n",
    "    for col, trace, cvt in zip(df.columns, traces, cvts):\n",
    "        print(adjust(col), ':: ', adjust(round(trace,2), 9), \">\", adjust(cvt, 8), ' =>  ' , trace > cvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe5692",
   "metadata": {},
   "outputs": [],
   "source": [
    "cointegration_test(var_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d367f252",
   "metadata": {},
   "source": [
    "### Step 2: Transforming the Time Series to be Stationary\n",
    "In order to perform our VAR test, we want our time series to be stationary. A stationary time series is one whose characteristics like mean and variance does not change over time. This is similar to what we have done with ARIMA model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1013ec8",
   "metadata": {},
   "source": [
    "Augmented Dickey Fuller test (ADFuller or ADF Test) is a common statistical test used to test whether a given Time series is stationary or not. It is one of the most commonly used statistical test when it comes to analyzing the stationary of a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15559fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adfuller_test(series, signif=0.05, name='', verbose=False):\n",
    "    \"\"\"Perform ADFuller to test for Stationarity of given series and print report\"\"\"\n",
    "    r = adfuller(series, autolag='AIC')\n",
    "    output = {'test_statistic':round(r[0], 4), 'pvalue':round(r[1], 4), 'n_lags':round(r[2], 4), 'n_obs':r[3]}\n",
    "    p_value = output['pvalue'] \n",
    "    def adjust(val, length= 6): return str(val).ljust(length)\n",
    "\n",
    "    # Print Summary\n",
    "    print(f'    Augmented Dickey-Fuller Test on \"{name}\"', \"\\n   \", '-'*47)\n",
    "    print(f' Null Hypothesis: Data has unit root. Non-Stationary.')\n",
    "    print(f' Significance Level    = {signif}')\n",
    "    print(f' Test Statistic        = {output[\"test_statistic\"]}')\n",
    "    print(f' No. Lags Chosen       = {output[\"n_lags\"]}')\n",
    "\n",
    "    for key,val in r[4].items():\n",
    "        print(f' Critical value {adjust(key)} = {round(val, 3)}')\n",
    "\n",
    "    if p_value <= signif:\n",
    "        print(f\" => P-Value = {p_value}. Rejecting Null Hypothesis.\")\n",
    "        print(f\" => Series is Stationary.\")\n",
    "    else:\n",
    "        print(f\" => P-Value = {p_value}. Weak evidence to reject the Null Hypothesis.\")\n",
    "        print(f\" => Series is Non-Stationary.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d21e3a",
   "metadata": {},
   "source": [
    "We will keep differencing the data series until we pass the ADFuller test for stationarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94911bf",
   "metadata": {},
   "source": [
    "#### First Iteration (with no differencing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41641520",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, column in df_train.iteritems():\n",
    "    adfuller_test(column, name=column.name)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e01774",
   "metadata": {},
   "source": [
    "#### Second Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8197743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_differenced = df_train.diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbcda70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADF Test on each column of 1st Differences Dataframe\n",
    "for name, column in df_differenced.iteritems():\n",
    "    adfuller_test(column, name=column.name)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c6c17",
   "metadata": {},
   "source": [
    "#### Third Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ec8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_differenced = df_differenced.diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a232fcfd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ADF Test on each column of 2nd Differences Dataframe\n",
    "for name, column in df_differenced.iteritems():\n",
    "    adfuller_test(column, name=column.name)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be9cb7",
   "metadata": {},
   "source": [
    "Now it seems that both series are stationary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7731ac",
   "metadata": {},
   "source": [
    "### Step 3: Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e170209a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = VAR(df_differenced)\n",
    "for i in [1,3,5,9]:\n",
    "    result = model.fit(i)\n",
    "    print('Lag Order =', i)\n",
    "    print('AIC : ', result.aic)\n",
    "    print('BIC : ', result.bic)\n",
    "    print('FPE : ', result.fpe)\n",
    "    print('HQIC: ', result.hqic, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54562f1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_fitted = model.fit(3)\n",
    "model_fitted.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f3624c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "def adjust(val, length= 6): return str(val).ljust(length)\n",
    "out = durbin_watson(model_fitted.resid)\n",
    "\n",
    "for col, val in zip(df_differenced.columns, out):\n",
    "    print(adjust(col), ':', round(val, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8bcde4",
   "metadata": {},
   "source": [
    "### Step 4: Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lag order\n",
    "lag_order = model_fitted.k_ar\n",
    "print(lag_order)  #> 4\n",
    "\n",
    "# Input data for forecasting\n",
    "forecast_input = df_differenced.values[-lag_order:]\n",
    "forecast_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7659dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Forecast\n",
    "fc = model_fitted.forecast(y=forecast_input, steps=nobs)\n",
    "df_forecast = pd.DataFrame(fc, index=var_df.index[-nobs:], columns=var_df.columns + '_2d')\n",
    "df_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1450ac",
   "metadata": {},
   "source": [
    "These are the differenced results. We want to de-difference it to get it back in terms of the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c38772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_transformation(df_train, df_forecast, second_diff=False):\n",
    "    \"\"\"Revert back the differencing to get the forecast to original scale.\"\"\"\n",
    "    df_fc = df_forecast.copy()\n",
    "    columns = df_train.columns\n",
    "    for col in columns:        \n",
    "        # Roll back 2nd Diff\n",
    "        if second_diff:\n",
    "            df_fc[str(col)+'_1d'] = (df_train[col].iloc[-1]-df_train[col].iloc[-2]) + df_fc[str(col)+'_2d'].cumsum()\n",
    "        # Roll back 1st Diff\n",
    "        df_fc[str(col)+'_forecast'] = df_train[col].iloc[-1] + df_fc[str(col)+'_1d'].cumsum()\n",
    "    return df_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadd32ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_results = invert_transformation(df_train, df_forecast, second_diff=True)        \n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee455b",
   "metadata": {},
   "source": [
    "We plot our predictions against actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227874d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=int(len(var_df.columns)/2), ncols=2, dpi=150, figsize=(12,6))\n",
    "for i, (col,ax) in enumerate(zip(var_df.columns, axes.flatten())):\n",
    "    df_results[col+'_forecast'].plot(legend=True, ax=ax).autoscale(axis='x',tight=True)\n",
    "    df_test[col][-nobs:].plot(legend=True, ax=ax);\n",
    "    ax.set_title(col + \": Forecast vs Actual\")\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax.spines[\"top\"].set_alpha(0)\n",
    "    ax.tick_params(labelsize=6)\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e114c98",
   "metadata": {},
   "source": [
    "### Step 5: Finding RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31adcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "def forecast_accuracy(forecast, actual):\n",
    "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  # MAPE\n",
    "    me = np.mean(forecast - actual)             # ME\n",
    "    mae = np.mean(np.abs(forecast - actual))    # MAE\n",
    "    mpe = np.mean((forecast - actual)/actual)   # MPE\n",
    "    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n",
    "    corr = np.corrcoef(forecast, actual)[0,1]   # corr\n",
    "    mins = np.amin(np.hstack([forecast[:,None], \n",
    "                              actual[:,None]]), axis=1)\n",
    "    maxs = np.amax(np.hstack([forecast[:,None], \n",
    "                              actual[:,None]]), axis=1)\n",
    "    minmax = 1 - np.mean(mins/maxs)             # minmax\n",
    "    return({'mape':mape, 'me':me, 'mae': mae, \n",
    "            'mpe': mpe, 'rmse':rmse, 'corr':corr, 'minmax':minmax})\n",
    "\n",
    "print('Forecast Accuracy of: ZORI')\n",
    "accuracy_prod = forecast_accuracy(df_results['ZORI_forecast'].values, df_test['ZORI'])\n",
    "for k, v in accuracy_prod.items():\n",
    "    print(adjust(k), ': ', round(v,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc6b3ba",
   "metadata": {},
   "source": [
    "**Congrats on making it to the end of the lab!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abab8ec",
   "metadata": {},
   "source": [
    "---\n",
    "## Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c1ec2",
   "metadata": {},
   "source": [
    "**Question 4:** Please fill out this short [feedback form](https://forms.gle/VwKv8efSwPwYNQve8) to let us know your thoughts about this lab! We really appreciate your opinions and feedback! At the end of the Google form, you should see a codeword. Assign the codeword to the variable `codeword` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbdbab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "codeword = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e64a160",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436bc909",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ed56a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f85a9c",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "lab09",
   "tests": {
    "q1_3": {
     "name": "q1_3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> zillow.shape == (90, 2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.all(zillow.columns == ['DATE', 'ZORI'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> zillow['DATE'].iloc[0] == pd.to_datetime(\"2015-03-31\", format='%Y-%m-%d')\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(zillow['ZORI'].iloc[0], 1370.3018057532663)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_4": {
     "name": "q1_4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> train.shape == (81, 1)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> test.shape == (9, 1)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(train['CPI'].mean(), 320.21020987654316)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(test['CPI'].mean(), 366.08233333333334)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_1": {
     "name": "q2_1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q2_1 == 2\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_2": {
     "name": "q2_2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> y_pred_df.shape == (9, 3)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> arima_rmse <= 3.5\nTrue",
         "failure_message": "Here're some additional hints. In our locally optimal solution, we use relatively large d and q.",
         "hidden": false,
         "locked": false,
         "success_message": "Good job!"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_3": {
     "name": "q2_3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> m*0xec148 == 11603808\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_4": {
     "name": "q2_4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q2_4 == 1\nTrue",
         "hidden": false,
         "locked": false,
         "success_message": "Correct. Our CPI series is already a seasonally adjusted series!"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_1": {
     "name": "q3_1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> combined.shape == (90, 4)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(combined[\"log CPI\"].iloc[1:4:8], 5.649837)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(combined[\"log ZORI\"].iloc[1:4:8], 7.231266)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> sum([ord(c) for c in codeword])^0xec148 == 967490\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
